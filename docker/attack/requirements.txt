# Core ML/AI Libraries
torch==2.7.1
torchvision
transformers==4.48.2
datasets
accelerate>=1.3.0
peft==0.16.0
# trl==0.19.1

# Qwen VL specific dependencies
qwen-vl-utils

# Training and evaluation
deepspeed==0.17.2
evaluate
numpy
scipy
scikit-learn
mpi4py

#fp8 support
transformer-engine

# Data processing
pandas
pillow
pyarrow

# Configuration and argument parsing
tyro
pyyaml

# Utilities
tqdm
requests
huggingface-hub==0.33.2
safetensors
tokenizers==0.21.1

# GPU monitoring
pynvml
nvidia-ml-py>=12.560.30

# # CUDA dependencies (if using GPU) - Compatible with torch 2.7.1
nvidia-cublas-cu12>=12.6.0
nvidia-cuda-cupti-cu12>=12.6.0
nvidia-cuda-nvrtc-cu12>=12.6.0
nvidia-cuda-runtime-cu12>=12.6.0
nvidia-cudnn-cu12>=9.1.0.70
nvidia-cufft-cu12>=11.2.1.3
nvidia-curand-cu12>=10.3.5.147
nvidia-cusolver-cu12>=11.6.1.9
nvidia-cusparse-cu12==12.5.4.2
nvidia-nccl-cu12>=2.21.5
nvidia-nvjitlink-cu12>=12.6.0
nvidia-nvtx-cu12>=12.6.0

# Optional optimizations
triton>=3.3.1

# Standard Python utilities
packaging
ninja
regex
filelock
fsspec
jinja2
typing-extensions
