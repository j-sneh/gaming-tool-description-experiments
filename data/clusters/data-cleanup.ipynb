{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89f385c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a0e684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BOOLEAN', 'ENUM', 'STRING', 'DATE (YYYY-MM-DD)', 'NUMBER', 'string'}\n"
     ]
    }
   ],
   "source": [
    "# Load toolbench bias queries\n",
    "with open(\"toolbench_bias_queries.json\", \"r\") as input_file, open(\"cluster_queries.json\", \"r\") as cluster_queries_file, open(\"bias_dataset_bfcl_format.jsonl\", \"w\") as output_file:\n",
    "    # TODO: incorporate return values and api endpoint info into the description\n",
    "    toolbench_bias_queries = json.load(input_file)\n",
    "    cluster_queries = json.load(cluster_queries_file)\n",
    "    \n",
    "    cluster_id = 0\n",
    "    types = set()\n",
    "\n",
    "    clusters = []\n",
    "\n",
    "    # Decisions for converting to OpenAI format:\n",
    "    # 1. Function Name will be: f{tool_name}.{api_name} (both converted to snake_case) \n",
    "    # 2. Parameters will be \"parameters\": {\"type\":\"object\", \"properties\": {\"{param_name}\": {\"type\": \"{type}\", \"description\": \"{description}\"}}, required: [\"{param_name}\"]}\n",
    "\n",
    "\n",
    "    # For Types\n",
    "    # ENUM, string, STRING --> string\n",
    "    # DATE (YYYY-MM-DD) --> string\n",
    "    # BOOLEAN --> boolean\n",
    "    # NUMBER --> float\n",
    "    type_mapping = {\n",
    "        \"ENUM\": \"string\",\n",
    "        \"DATE (YYYY-MM-DD)\": \"string\",\n",
    "        \"BOOLEAN\": \"boolean\",\n",
    "        \"NUMBER\": \"float\",\n",
    "        \"STRING\": \"string\",\n",
    "        \"string\": \"string\",\n",
    "    }\n",
    "\n",
    "    cluster_id = 1\n",
    "    for idx in range(0, len(toolbench_bias_queries), 500):\n",
    "        apis = toolbench_bias_queries[idx]['api_list']\n",
    "\n",
    "        formatted_tools = []\n",
    "\n",
    "        \n",
    "        for api in apis:\n",
    "            # Convert to snake_case\n",
    "            api_name = api['api_name'].lower()\n",
    "            tool_name = api['tool_name'].lower()\n",
    "\n",
    "            function_name = f\"{tool_name}.{api_name}\".replace(\" \", \"_\").replace(\"-\", \"_\").replace(\"/\", \"_\")\n",
    "\n",
    "            # remove any non-alphanumeric characters\n",
    "            function_name = re.sub(r'[^a-zA-Z0-9_\\.]', '', function_name)\n",
    "            \n",
    "\n",
    "            # Convert to OpenAI format\n",
    "            required = []\n",
    "            properties = {}\n",
    "            for param in api['required_parameters']:\n",
    "                types.add(param['type'])\n",
    "                properties[param['name']] = {\n",
    "                    \"type\": type_mapping[param['type']],\n",
    "                    \"description\": param['description']\n",
    "                }\n",
    "                required.append(param['name'])\n",
    "\n",
    "            for param in api['optional_parameters']:\n",
    "                types.add(param['type'])\n",
    "                properties[param['name']] = {\n",
    "                    \"type\": type_mapping[param['type']],\n",
    "                    \"description\": param['description']\n",
    "                }\n",
    "\n",
    "            formatted_tools.append({\n",
    "                \"name\": function_name,\n",
    "                \"description\": api.get('api_description', ''),\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": properties,\n",
    "                    \"required\": required\n",
    "                }})\n",
    "        assert cluster_id == cluster_queries[cluster_id - 1]['cluster_id']\n",
    "        clusters.append({\"id\": f\"bias-{cluster_id}\", \"function\": \n",
    "        formatted_tools, \"question\": [[{\"role\": \"user\", \"content\": query}] for query in cluster_queries[cluster_id - 1]['queries']]})\n",
    "        cluster_id += 1\n",
    "    \n",
    "    print(types)\n",
    "\n",
    "    # generate jsonl\n",
    "    for cluster in clusters:\n",
    "        output_file.write(json.dumps(cluster) + \"\\n\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44bccbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goapis_geocoding_api.geocding\n",
      "geocode___forward_and_reverse.forward_geocode\n",
      "geolocate.get_coordinates\n",
      "trueway_geocoding.geocode\n",
      "geokeo_forward_geocoding.search.php\n",
      "geocode___forward_and_reverse.reverse_geocode\n",
      "forward__reverse_geocoding.reversegeocoding\n",
      "geocoding_by_api_ninjas._v1_reversegeocoding\n",
      "address_from_to_latitude_longitude.coordinates_latitude_longitude_to_address\n",
      "feroeg___reverse_geocoding.reversegeocode\n",
      "real_time_news_data.topic_headlines\n",
      "newscatcher._v1_latest_headlines\n",
      "theclique.top_headlines\n",
      "newsdata.news\n",
      "web_search.newssearch\n",
      "ip_geolocation_find_ip_location_and_ip_info.get_ip_geolocation\n",
      "ip_geolocalization_api.ip_address_lookup\n",
      "free_ip_geolocation.any_ip\n",
      "ip_address_geolocation.ip_geolocation\n",
      "ip_geo_location___find_ip_location_and_details.iplocation\n",
      "domain_whois_lookup_api.domain_name\n",
      "whois_by_api_ninjas._v1_whois\n",
      "newly_registered_domains.whois\n",
      "whois_v2.whois_lookup_v2\n",
      "whois_.whois\n",
      "validate_email.validate_email\n",
      "email_validator._email_validator_validate\n",
      "email_verifier.verify_email\n",
      "email_validation_and_verification.email_validation_api\n",
      "email_checker_and_validator.check_email\n",
      "sentiment_analysis_service.analyze_text\n",
      "multi_lingual_sentiment_analysis.sentiment_analysis\n",
      "textsentai_____ai_powered_text_sentiment_analyzer_.textsentai_api_\n",
      "sentiment_by_api_ninjas._v1_sentiment\n",
      "sentiment_analysis_v12.text_analysis\n",
      "whats_language.languagedetection\n",
      "quick_language_detector.detect_language\n",
      "text_language_by_api_ninjas._v1_textlanguage\n",
      "translate_v3.fast_language_detection\n",
      "translate_all_languages.detect\n",
      "qr_code_api_v33.qr_code_image\n",
      "qr_code_api_v67.qr_code_image_copy\n",
      "qr_code_generator_v14.generate_qr_code\n",
      "qr_code_api_generator.qr_code_generator\n",
      "easy_qr_code_generator.create_qr_code\n",
      "forecast.rapidapigetforecastsummarybycoordinates\n",
      "weatherapi.com.forecast_weather_api\n",
      "world_weather_online_api.local_weather_api\n",
      "weather.16_day_forecast\n",
      "weather_forecast_14_days.get_forecastdata_by_lat_lon\n"
     ]
    }
   ],
   "source": [
    "# read all names from bias_dataset_bfcl_format.jsonl\n",
    "with open(\"bias_dataset_bfcl_format.jsonl\", \"r\") as file:\n",
    "    names = [func[\"name\"] for line in file for func in json.loads(line)[\"function\"]]\n",
    "    for name in names:\n",
    "        print(name)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
